





# Kiến Trúc Cơ Sở Dữ Liệu trong Hệ Thống DocumentAI

Trong hệ thống DocumentAI, lớp Database Layer đóng vai trò quan trọng trong việc lưu trữ và quản lý dữ liệu. Dưới đây là chi tiết kiến trúc cơ sở dữ liệu và cách tổ chức lưu trữ trong hệ thống:

## I. PostgreSQL - Cơ Sở Dữ Liệu Quan Hệ

PostgreSQL được sử dụng để lưu trữ dữ liệu có cấu trúc, metadata, thông tin người dùng và trạng thái hệ thống.

### 1. Schema Chính

#### Bảng `users`
```sql
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    username VARCHAR(100) NOT NULL UNIQUE,
    email VARCHAR(255) NOT NULL UNIQUE,
    password_hash VARCHAR(255) NOT NULL,
    full_name VARCHAR(255),
    role VARCHAR(50) DEFAULT 'user',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    last_login TIMESTAMP WITH TIME ZONE,
    is_active BOOLEAN DEFAULT TRUE,
    preferences JSONB
);
```

#### Bảng `documents`
```sql
CREATE TABLE documents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    filename VARCHAR(255) NOT NULL,
    original_filename VARCHAR(255) NOT NULL,
    document_type VARCHAR(100),
    mime_type VARCHAR(100) NOT NULL,
    file_path VARCHAR(512) NOT NULL,
    file_size BIGINT,
    status VARCHAR(50) DEFAULT 'uploaded',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    processed_at TIMESTAMP WITH TIME ZONE,
    summary TEXT,
    metadata JSONB,
    tags TEXT[],
    is_deleted BOOLEAN DEFAULT FALSE
);

-- Indexes để tối ưu truy vấn
CREATE INDEX idx_documents_user_id ON documents(user_id);
CREATE INDEX idx_documents_status ON documents(status);
CREATE INDEX idx_documents_created_at ON documents(created_at);
CREATE INDEX idx_documents_document_type ON documents(document_type);
```

#### Bảng `document_chunks`
```sql
CREATE TABLE document_chunks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    document_id UUID REFERENCES documents(id) ON DELETE CASCADE,
    chunk_index INTEGER NOT NULL,
    content TEXT NOT NULL,
    token_count INTEGER,
    embedding_id VARCHAR(255),
    metadata JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    
    UNIQUE(document_id, chunk_index)
);

CREATE INDEX idx_document_chunks_document_id ON document_chunks(document_id);
```

#### Bảng `visualizations`
```sql
CREATE TABLE visualizations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    document_id UUID REFERENCES documents(id) ON DELETE CASCADE,
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    title VARCHAR(255),
    visualization_type VARCHAR(100) NOT NULL,
    file_path VARCHAR(512) NOT NULL,
    parameters JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    is_deleted BOOLEAN DEFAULT FALSE
);

CREATE INDEX idx_visualizations_document_id ON visualizations(document_id);
CREATE INDEX idx_visualizations_user_id ON visualizations(user_id);
```

#### Bảng `queries`
```sql
CREATE TABLE queries (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    query_text TEXT NOT NULL,
    response_text TEXT,
    document_ids UUID[] NOT NULL,
    embedding_id VARCHAR(255),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    metadata JSONB
);

CREATE INDEX idx_queries_user_id ON queries(user_id);
CREATE INDEX idx_queries_created_at ON queries(created_at);
```

### 2. Transactions và Consistency

Để đảm bảo tính nhất quán của dữ liệu, DocumentAI sử dụng các transactions khi cần cập nhật nhiều bảng liên quan:

```python
async def update_document_status(document_id, status, summary=None, metadata=None):
    async with db.transaction():
        # Cập nhật document
        await db.execute(
            """
            UPDATE documents 
            SET status = $1, 
                summary = COALESCE($2, summary), 
                metadata = COALESCE($3, metadata),
                updated_at = CURRENT_TIMESTAMP,
                processed_at = CASE WHEN $1 = 'processed' THEN CURRENT_TIMESTAMP ELSE processed_at END
            WHERE id = $4
            """,
            status, summary, metadata, document_id
        )
        
        # Tạo lịch sử trạng thái
        await db.execute(
            """
            INSERT INTO document_status_history(document_id, status, metadata)
            VALUES ($1, $2, $3)
            """,
            document_id, status, metadata
        )
```

## II. Vector Database (Pinecone/Weaviate)

Vector Database lưu trữ các embeddings (biểu diễn vector) của các đoạn văn bản, cho phép tìm kiếm ngữ nghĩa và RAG (Retrieval Augmented Generation).

### 1. Cấu Trúc Lưu Trữ trong Pinecone

Trong Pinecone, dữ liệu được tổ chức trong các chỉ mục (index) và namespace:

```python
# Định nghĩa cấu trúc Index
index_definition = {
    "name": "documentai-embeddings",
    "dimension": 1536,  # OpenAI ada-002 embedding dimension
    "metric": "cosine",  # Similarity metric
    "pods": 2,
    "pod_type": "p1.x1"  # Loại pod cho hiệu suất
}

# Vector metadata
vector_metadata = {
    "document_id": "b87a56e2-3e21-4c11-8f3c-c92d4c13823a",
    "chunk_id": "b87a56e2-3e21-4c11-8f3c-c92d4c13823a_chunk_0",
    "chunk_index": 0,
    "document_type": "brd",
    "token_count": 512,
    "user_id": "7f6d9e15-8a2d-47f8-b2e7-4da3510b1ec7",
    "created_at": "2023-12-01T10:15:23Z",
    "source": "documents/b87a56e2-3e21-4c11-8f3c-c92d4c13823a.pdf"
}
```

### 2. Ví Dụ Truy Vấn Pinecone

```python
# Tìm kiếm vectors tương tự
def search_similar_vectors(query_embedding, document_ids=None, top_k=5):
    # Cấu hình filter nếu cần giới hạn theo document_ids
    filter_config = None
    if document_ids:
        filter_config = {
            "document_id": {"$in": document_ids}
        }
    
    # Thực hiện tìm kiếm
    results = pinecone_index.query(
        vector=query_embedding,
        top_k=top_k,
        include_metadata=True,
        filter=filter_config
    )
    
    return results
```

### 3. Cấu Trúc Weaviate (Lựa Chọn Thay Thế)

Nếu sử dụng Weaviate, dữ liệu được tổ chức theo schema hướng đối tượng:

```python
# Định nghĩa schema
document_chunk_class = {
    "class": "DocumentChunk",
    "vectorizer": "none",  # Sử dụng embeddings được tính toán bên ngoài
    "properties": [
        {
            "name": "content",
            "dataType": ["text"],
            "description": "The content of the document chunk"
        },
        {
            "name": "documentId",
            "dataType": ["string"],
            "description": "ID of the parent document"
        },
        {
            "name": "chunkIndex",
            "dataType": ["int"],
            "description": "Index of the chunk within document"
        },
        {
            "name": "documentType",
            "dataType": ["string"],
            "description": "Type of document (BRD, API spec, etc)"
        },
        {
            "name": "userId",
            "dataType": ["string"],
            "description": "Owner of the document"
        },
        {
            "name": "tokenCount",
            "dataType": ["int"],
            "description": "Number of tokens in the chunk"
        }
    ]
}
```

## III. Object Storage (MinIO)

MinIO/S3 được sử dụng để lưu trữ các tệp gốc, tệp đã xử lý, và kết quả trực quan hóa.

---> Thêm tính năng gợi ý câu hỏi về tài liệu

### 1. Cấu Trúc Bucket và Tổ Chức

```
documentai/
├── raw-documents/                # Tài liệu gốc người dùng tải lên
│   └── {user_id}/
│       └── {document_id}/
│           └── original.{ext}
├── processed-documents/          # Tài liệu đã xử lý
│   └── {user_id}/
│       └── {document_id}/
│           ├── extracted_text.txt
│           ├── metadata.json
│           └── chunks/
│               ├── chunk_0.txt
│               ├── chunk_1.txt
│               └── ...
├── visualizations/               # Kết quả trực quan hóa
│   └── {user_id}/
│       └── {visualization_id}/
│           ├── diagram.svg
│           ├── diagram.png
│           └── metadata.json
└── exports/                      # Kết quả chuẩn hóa
    └── {user_id}/
        └── {export_id}/
            ├── agile_stories.docx
            ├── jira_export.json
            └── gantt_chart.pdf
```

### 2. Quản Lý Vòng Đời Object

```python
# Ví dụ về chính sách vòng đời object trong MinIO
lifecycle_config = {
    "Rules": [
        {
            "ID": "delete-old-temp-files",
            "Status": "Enabled",
            "Filter": {
                "Prefix": "temp/"
            },
            "Expiration": {
                "Days": 1
            }
        },
        {
            "ID": "archive-old-documents",
            "Status": "Enabled",
            "Filter": {
                "Prefix": "raw-documents/"
            },
            "Transition": {
                "Days": 90,
                "StorageClass": "GLACIER"
            }
        }
    ]
}
```

## IV. Tích Hợp Giữa Các Cơ Sở Dữ Liệu

Việc tích hợp giữa các cơ sở dữ liệu là quan trọng để đảm bảo tính nhất quán và hiệu suất:

### 1. Liên Kết PostgreSQL và Vector Database

```python
# Thêm một chunk mới vào cả PostgreSQL và Vector Database
async def add_document_chunk(document_id, chunk_index, content, embedding):
    # 1. Thêm vào PostgreSQL
    db_result = await db.fetchrow(
        """
        INSERT INTO document_chunks(document_id, chunk_index, content, token_count)
        VALUES ($1, $2, $3, $4)
        RETURNING id
        """,
        document_id, chunk_index, content, len(content.split())
    )
    chunk_id = db_result['id']
    
    # 2. Thêm vào Vector Database
    vector_id = f"{document_id}_chunk_{chunk_index}"
    
    # Truy vấn metadata
    metadata = await db.fetchrow(
        """
        SELECT d.document_type, d.user_id, d.created_at
        FROM documents d
        WHERE d.id = $1
        """,
        document_id
    )
    
    # Lưu vector embedding
    pinecone_index.upsert(
        vectors=[
            {
                "id": vector_id,
                "values": embedding,
                "metadata": {
                    "document_id": str(document_id),
                    "chunk_id": str(chunk_id),
                    "chunk_index": chunk_index,
                    "document_type": metadata['document_type'],
                    "user_id": str(metadata['user_id']),
                    "created_at": metadata['created_at'].isoformat()
                }
            }
        ]
    )
    
    # 3. Cập nhật reference trong PostgreSQL
    await db.execute(
        """
        UPDATE document_chunks
        SET embedding_id = $1
        WHERE id = $2
        """,
        vector_id, chunk_id
    )
    
    return chunk_id, vector_id
```

### 2. Xử Lý Sự Cố và Khôi Phục

```python
# Kiểm tra và sửa chữa dữ liệu không đồng bộ
async def verify_and_repair_embeddings():
    # 1. Tìm các chunks không có embedding_id
    missing_embedding_chunks = await db.fetch(
        """
        SELECT id, document_id, chunk_index, content
        FROM document_chunks
        WHERE embedding_id IS NULL
        """
    )
    
    for chunk in missing_embedding_chunks:
        # Tạo embedding
        embedding = await generate_embedding(chunk['content'])
        
        # Thêm vào vector database và cập nhật PostgreSQL
        await add_embedding_for_chunk(
            chunk['id'],
            chunk['document_id'],
            chunk['chunk_index'],
            embedding
        )
    
    # 2. Kiểm tra vector không có liên kết trong SQL
    # (Triển khai tùy thuộc vào cách cụ thể của vector DB)
```

## V. Vector Database - Thành Phần Quan Trọng Nhất

Vector Database là thành phần quan trọng nhất trong kiến trúc cơ sở dữ liệu của DocumentAI, vì nó cho phép tìm kiếm ngữ nghĩa và RAG, làm nền tảng cho khả năng hiểu và truy xuất thông tin thông minh từ tài liệu.

### 1. Cấu Trúc Vector và Metadata Chi Tiết

Chi tiết về cấu trúc lưu trữ vector trong Pinecone:

```
{
  "id": "doc123_chunk_7",  // Vector ID (document_id + chunk_index)
  "values": [0.1, 0.2, ..., 0.5],  // Embedding vector (1536 dimensions)
  "metadata": {
    // Document metadata
    "document_id": "doc123",
    "document_name": "System Architecture.pdf",
    "document_type": "architecture",
    "user_id": "user456",
    
    // Chunk metadata
    "chunk_id": "chunk789",
    "chunk_index": 7,
    "token_count": 512,
    "page_number": 12,
    "section": "Database Design",
    
    // Content metadata (helps with filtering)
    "contains_diagram": true,
    "contains_code": false,
    "programming_languages": ["SQL"],
    "entities": ["PostgreSQL", "Vector Database", "MinIO"],
    "created_at": "2024-03-01T14:32:10Z",
    "language": "en"
  }
}
```

### 2. Ví Dụ Tìm Kiếm Nâng Cao

```python
async def semantic_search(query, filters=None, top_k=5):
    # Tạo embedding cho câu query
    query_embedding = await generate_embedding(query)
    
    # Xây dựng filter
    filter_dict = {}
    
    if filters:
        if 'document_types' in filters:
            filter_dict["document_type"] = {"$in": filters['document_types']}
        
        if 'user_id' in filters:
            filter_dict["user_id"] = filters['user_id']
            
        if 'date_range' in filters:
            filter_dict["created_at"] = {
                "$gte": filters['date_range']['start'],
                "$lte": filters['date_range']['end']
            }
        
        if 'entities' in filters:
            filter_dict["entities"] = {"$in": filters['entities']}
    
    # Thực hiện tìm kiếm
    results = pinecone_index.query(
        vector=query_embedding,
        top_k=top_k,
        include_metadata=True,
        filter=filter_dict
    )
    
    # Xử lý kết quả
    processed_results = []
    for match in results.matches:
        # Truy vấn nội dung đầy đủ từ PostgreSQL nếu cần
        chunk_content = await db.fetchval(
            """
            SELECT content FROM document_chunks
            WHERE document_id = $1 AND chunk_index = $2
            """,
            match.metadata['document_id'],
            match.metadata['chunk_index']
        )
        
        processed_results.append({
            "id": match.id,
            "score": match.score,
            "content": chunk_content,
            "document_id": match.metadata['document_id'],
            "document_name": match.metadata.get('document_name', 'Unknown'),
            "chunk_index": match.metadata['chunk_index'],
            "section": match.metadata.get('section', 'Unknown')
        })
    
    return processed_results
```

### 3. Quản Lý Hybrid Search

Kết hợp vector search với keyword search để cải thiện kết quả:

```python
async def hybrid_search(query, filters=None, top_k=5):
    # 1. Semantic search với vector
    vector_results = await semantic_search(query, filters, top_k=top_k*2)
    
    # 2. Keyword search trong PostgreSQL
    keywords = extract_keywords(query)
    if keywords:
        keyword_query = ' & '.join(keywords)
        
        # Tạo full-text search query
        keyword_results = await db.fetch(
            """
            SELECT 
                dc.document_id,
                dc.chunk_index,
                dc.content,
                d.filename as document_name,
                ts_rank_cd(to_tsvector('english', dc.content), to_tsquery('english', $1)) as rank
            FROM 
                document_chunks dc
            JOIN 
                documents d ON dc.document_id = d.id
            WHERE 
                to_tsvector('english', dc.content) @@ to_tsquery('english', $1)
            ORDER BY 
                rank DESC
            LIMIT $2
            """,
            keyword_query, top_k*2
        )
        
        # Convert to similar format as vector results
        processed_keyword_results = [{
            "id": f"{row['document_id']}_chunk_{row['chunk_index']}",
            "score": row['rank'],
            "content": row['content'],
            "document_id": row['document_id'],
            "document_name": row['document_name'],
            "chunk_index": row['chunk_index'],
            "source": "keyword"
        } for row in keyword_results]
        
        # 3. Merge results (hybrid approach)
        merged_results = merge_and_rank_results(vector_results, processed_keyword_results, top_k)
        return merged_results
    
    # Nếu không có keyword hữu ích, chỉ trả về vector results
    return vector_results[:top_k]
```

### 4. Reranking và Hybrid Retrieval

```python
def merge_and_rank_results(vector_results, keyword_results, top_k):
    # Create a dictionary to store all results with scores
    all_results = {}
    
    # Process vector results (semantic similarity)
    for result in vector_results:
        id = result["id"]
        all_results[id] = {
            **result,
            "semantic_score": result["score"],
            "keyword_score": 0,
            "final_score": result["score"] * 0.7  # Weight semantic score at 70%
        }
    
    # Process keyword results
    for result in keyword_results:
        id = result["id"]
        if id in all_results:
            # If already exists from semantic search, update scores
            all_results[id]["keyword_score"] = result["score"]
            all_results[id]["final_score"] += result["score"] * 0.3  # Weight keyword score at 30%
        else:
            # New result from keyword search
            all_results[id] = {
                **result,
                "semantic_score": 0,
                "keyword_score": result["score"],
                "final_score": result["score"] * 0.3  # Only keyword score
            }
    
    # Convert dictionary to list and sort by final score
    merged_list = list(all_results.values())
    merged_list.sort(key=lambda x: x["final_score"], reverse=True)
    
    # Return top_k results
    return merged_list[:top_k]
```

Kết hợp giữa các cơ sở dữ liệu này tạo nên một hệ thống mạnh mẽ có khả năng lưu trữ, truy vấn và phân tích các tài liệu dự án hiệu quả, tạo nền tảng vững chắc cho các tính năng AI cao cấp của DocumentAI.